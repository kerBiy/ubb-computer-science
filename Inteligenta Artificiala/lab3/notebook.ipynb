{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "# from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "# from array import array\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# import sys\n",
    "import time\n",
    "# import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T14:03:54.345336Z",
     "start_time": "2025-03-18T14:03:54.335567Z"
    }
   },
   "id": "49355ce1f6196feb",
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "'''\n",
    "Authenticate\n",
    "Authenticates your credentials and creates a client.\n",
    "'''\n",
    "subscription_key = \"5i200akRHXqb0YuDuEl7cPbt9p68P3nsm6Lxr28wG6HqqVhjWyHUJQQJ99BCACi5YpzXJ3w3AAAFACOGbqGn\"\n",
    "endpoint = \"https://alexbalta.cognitiveservices.azure.com/\"\n",
    "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))\n",
    "'''\n",
    "END - Authenticate\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T14:03:54.379408Z",
     "start_time": "2025-03-18T14:03:54.367920Z"
    }
   },
   "id": "40b580057830a9bd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEND - Authenticate\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "# img = open(\"test1.png\", \"rb\")\n",
    "img = open(\"test2.jpeg\", \"rb\")\n",
    "read_response = computervision_client.read_in_stream(\n",
    "    image=img,\n",
    "    mode=\"Printed\",\n",
    "    raw=True\n",
    ")\n",
    "# print(read_response.as_dict())\n",
    "\n",
    "operation_id = read_response.headers['Operation-Location'].split('/')[-1]\n",
    "while True:\n",
    "    read_result = computervision_client.get_read_result(operation_id)\n",
    "    if read_result.status not in ['notStarted', 'running']:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# Print the detected text, line by line\n",
    "result = []\n",
    "if read_result.status == OperationStatusCodes.succeeded:\n",
    "    for text_result in read_result.analyze_result.read_results:\n",
    "        for line in text_result.lines:\n",
    "            print(line.text)\n",
    "            result.append(line.text)\n",
    "\n",
    "print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T14:03:56.606921Z",
     "start_time": "2025-03-18T14:03:54.392143Z"
    }
   },
   "id": "d8783faef84fc7a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lucces in resolvarea\n",
      "TEMELOR la\n",
      "LABORA toarele de\n",
      "Inteligenta Artificialà!\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "from statistics import mean\n",
    "\n",
    "from Levenshtein import distance as lev_dis\n",
    "from Levenshtein import jaro_winkler\n",
    "from jiwer import wer\n",
    "\n",
    "\n",
    "def evaluate_ocr_words(ground_truth, recognized_text):\n",
    "    wer_score = wer(ground_truth, recognized_text)\n",
    "    return wer_score\n",
    "\n",
    "\n",
    "def calculate_jaro_winkler_similarity(gt_text, ocr_text):\n",
    "    return jaro_winkler(gt_text, ocr_text) * 100\n",
    "\n",
    "\n",
    "def calculate_character_level_accuracy(gt_text, ocr_text):\n",
    "    dist = lev_dis(gt_text, ocr_text)\n",
    "    max_len = max(len(gt_text), len(ocr_text))\n",
    "    accuracy = (1 - dist / max_len) * 100 if max_len > 0 else 0\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def calculate_word_level_accuracy(gt_text, ocr_text):\n",
    "    gt_words = gt_text.split()\n",
    "    ocr_words = ocr_text.split()\n",
    "    common = sum(1 for w1, w2 in zip(gt_words, ocr_words) if w1 == w2)\n",
    "    return (common / max(len(gt_words), len(ocr_words))) * 100 if gt_words else 0\n",
    "\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "    intersection = len(set1 & set2)\n",
    "    union = len(set1 | set2)\n",
    "    return (intersection / union) * 100 if union > 0 else 0\n",
    "\n",
    "# get/define the ground truth\n",
    "# groundTruth = [\"Google Cloud\", \"Platform\"]\n",
    "groundTruth = [\"Succes in rezolvarea\", \"tEMELOR la\", \"LABORAtoaree de\", \"Inteligenta Artificiala!\"]\n",
    "\n",
    "# compute the performance\n",
    "noOfCorrectLines = sum(i == j for i, j in zip(result, groundTruth))\n",
    "errorLevCar = mean(calculate_character_level_accuracy(result[i],groundTruth[i]) for i in range(4))\n",
    "errorJarCar = mean(calculate_jaro_winkler_similarity(result[i],groundTruth[i]) for i in range(4))\n",
    "print(\"La nivel de caracter cu levenshtein: \" + str(errorLevCar))\n",
    "print(\"La nivel de caracter cu jaro-wrinkler: \" + str(errorJarCar))\n",
    "\n",
    "errorWord = mean(calculate_word_level_accuracy(result[i],groundTruth[i]) for i in range(4))\n",
    "errorWordWer = mean(evaluate_ocr_words(result[i],groundTruth[i]) for i in range(4))\n",
    "print(\"La nivel de cuvant: \" + str(errorWord))\n",
    "print(\"La nivel de cuvant wer: \" + str(errorWordWer*100))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T14:03:56.646457Z",
     "start_time": "2025-03-18T14:03:56.633113Z"
    }
   },
   "id": "22f2a6fecdf17b28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La nivel de caracter cu levenshtein: 91.0171568627451\n",
      "La nivel de caracter cu jaro-wrinkler: 94.66176470588235\n",
      "La nivel de cuvant: 33.33333333333333\n",
      "La nivel de cuvant wer: 58.33333333333333\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    # Determinăm coordonatele intersecției\n",
    "    x1_inter = max(box1[0], box2[0])\n",
    "    y1_inter = max(box1[1], box2[1])\n",
    "    x2_inter = min(box1[2], box2[2])\n",
    "    y2_inter = min(box1[3], box2[3])\n",
    "\n",
    "    # Dacă nu există intersecție, IoU este 0\n",
    "    if x1_inter >= x2_inter or y1_inter >= y2_inter:\n",
    "        return 0.0\n",
    "\n",
    "    # Calculăm aria intersecției\n",
    "    intersection_area = (x2_inter - x1_inter) * (y2_inter - y1_inter)\n",
    "\n",
    "    # Calculăm ariile fiecărei casete de delimitare\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "    # Calculăm aria uniunii\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "    # IoU = Intersecție / Uniune\n",
    "    return intersection_area / union_area\n",
    "\n",
    "# Funcție pentru procesarea imaginii și evaluarea localizării textului\n",
    "def evaluate_text_localization(image_path, ground_truth_boxes):\n",
    "    # Deschide fișierul imagine\n",
    "    with open(image_path, \"rb\") as img:\n",
    "        read_response = computervision_client.read_in_stream(\n",
    "            image=img,\n",
    "            mode=\"Printed\",\n",
    "            raw=True\n",
    "        )\n",
    "\n",
    "    operation_id = read_response.headers['Operation-Location'].split('/')[-1]\n",
    "    \n",
    "    # Așteptăm procesarea imaginii\n",
    "    while True:\n",
    "        read_result = computervision_client.get_read_result(operation_id)\n",
    "        if read_result.status not in ['notStarted', 'running']:\n",
    "            break\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Verificăm statusul procesului și obținem rezultatele\n",
    "    if read_result.status == OperationStatusCodes.succeeded:\n",
    "        detected_boxes = []\n",
    "        \n",
    "        for text_result in read_result.analyze_result.read_results:\n",
    "            for line in text_result.lines:\n",
    "                # Extragem coordonatele bounding box pentru fiecare linie\n",
    "                bounding_box = line.bounding_box\n",
    "                detected_boxes.append([bounding_box[0],bounding_box[1],bounding_box[4],bounding_box[5]])\n",
    "                print(f\"Text detectat: {line.text}\")\n",
    "                print(f\"Coordonate bounding box: {bounding_box}\")\n",
    "\n",
    "        # Calculăm IoU pentru fiecare casetă de text detectată și coordonatele de referință\n",
    "        iou_scores = []\n",
    "        for i in range(len(detected_boxes)):\n",
    "            iou = calculate_iou(detected_boxes[i], ground_truth_boxes[i])\n",
    "            iou_scores.append(iou)\n",
    "\n",
    "        # Afișăm scorurile IoU\n",
    "        for i, score in enumerate(iou_scores):\n",
    "            print(f\"Scor IoU {i+1}: {score:.2f}\")\n",
    "\n",
    "# Exemplu de utilizare\n",
    "image_path = \"test2.jpeg\"\n",
    "\n",
    "# Casete de referință (ground truth), coordonate [x1, y1, x2, y2] pentru fiecare zonă de text\n",
    "ground_truth_boxes = [\n",
    "    [62, 296, 1356, 480],  # Exemplu de coordonate pentru un text\n",
    "    [125, 572, 1059, 724],\n",
    "    [72, 925, 1022, 1036],\n",
    "    [99, 1129, 1466, 1375]# Alt exemplu de coordonate pentru un alt text\n",
    "]\n",
    "\n",
    "# Evaluăm localizarea textului\n",
    "evaluate_text_localization(image_path, ground_truth_boxes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T14:03:58.103950Z",
     "start_time": "2025-03-18T14:03:56.674089Z"
    }
   },
   "id": "691cc05ab09fc78c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text detectat: Lucces in resolvarea\n",
      "Coordonate bounding box: [86.0, 314.0, 1335.0, 287.0, 1336.0, 443.0, 86.0, 478.0]\n",
      "Text detectat: TEMELOR la\n",
      "Coordonate bounding box: [140.0, 590.0, 1045.0, 587.0, 1046.0, 723.0, 140.0, 727.0]\n",
      "Text detectat: LABORA toarele de\n",
      "Coordonate bounding box: [81.0, 915.0, 1007.0, 926.0, 1004.0, 1039.0, 78.0, 1014.0]\n",
      "Text detectat: Inteligenta Artificialà!\n",
      "Coordonate bounding box: [108.0, 1129.0, 1450.0, 1151.0, 1446.0, 1293.0, 105.0, 1259.0]\n",
      "Scor IoU 1: 0.68\n",
      "Scor IoU 2: 0.85\n",
      "Scor IoU 3: 0.87\n",
      "Scor IoU 4: 0.65\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def process_image(image_path):\n",
    "    # Citește imaginea\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # Convertire în grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imwrite(\"gray.jpg\", gray)\n",
    "\n",
    "    # Creșterea contrastului folosind CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    contrast = clahe.apply(gray)\n",
    "    cv2.imwrite(\"contrast.jpg\", contrast)\n",
    "\n",
    "    # Reducerea zgomotului cu Gaussian Blur\n",
    "    denoise = cv2.GaussianBlur(contrast, (5, 5), 0)\n",
    "    cv2.imwrite(\"denoise.jpg\", denoise)\n",
    "    \n",
    "    img2 = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    img2 = cv2.resize(img2, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imwrite(\"improve.jpg\", img2)\n",
    "\n",
    "# Exemplu de utilizare\n",
    "process_image(\"test2.jpeg\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T14:03:58.194132Z",
     "start_time": "2025-03-18T14:03:58.115625Z"
    }
   },
   "id": "d360c5f92096a456",
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "evaluate_text_localization(\"gray.jpg\",ground_truth_boxes)\n",
    "evaluate_text_localization(\"denoise.jpg\",ground_truth_boxes)\n",
    "evaluate_text_localization(\"contrast.jpg\",ground_truth_boxes)\n",
    "evaluate_text_localization(\"improve.jpg\",ground_truth_boxes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T14:04:03.844857Z",
     "start_time": "2025-03-18T14:03:58.198982Z"
    }
   },
   "id": "49322526d1a7c72f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text detectat: Lucces in resolvarea\n",
      "Coordonate bounding box: [87.0, 312.0, 1335.0, 289.0, 1336.0, 445.0, 87.0, 477.0]\n",
      "Text detectat: TEMELOR la\n",
      "Coordonate bounding box: [130.0, 592.0, 1044.0, 588.0, 1045.0, 720.0, 130.0, 726.0]\n",
      "Text detectat: LABORA toarele de\n",
      "Coordonate bounding box: [82.0, 916.0, 1005.0, 925.0, 1003.0, 1039.0, 79.0, 1015.0]\n",
      "Text detectat: Inteligenta Artificialà!\n",
      "Coordonate bounding box: [109.0, 1130.0, 1452.0, 1151.0, 1449.0, 1294.0, 106.0, 1260.0]\n",
      "Scor IoU 1: 0.70\n",
      "Scor IoU 2: 0.82\n",
      "Scor IoU 3: 0.88\n",
      "Scor IoU 4: 0.65\n",
      "Text detectat: Lucces in resolvarea\n",
      "Coordonate bounding box: [78.0, 337.0, 1332.0, 306.0, 1334.0, 431.0, 80.0, 473.0]\n",
      "Text detectat: TEMELOR la\n",
      "Coordonate bounding box: [138.0, 589.0, 1048.0, 584.0, 1049.0, 719.0, 139.0, 726.0]\n",
      "Text detectat: LABORA toarele de\n",
      "Coordonate bounding box: [79.0, 914.0, 1004.0, 924.0, 1003.0, 1038.0, 77.0, 1014.0]\n",
      "Text detectat: Inteligenta Artificialà!\n",
      "Coordonate bounding box: [103.0, 1129.0, 1454.0, 1155.0, 1450.0, 1294.0, 99.0, 1259.0]\n",
      "Scor IoU 1: 0.50\n",
      "Scor IoU 2: 0.83\n",
      "Scor IoU 3: 0.87\n",
      "Scor IoU 4: 0.66\n",
      "Text detectat: Lucces in resolvarea\n",
      "Coordonate bounding box: [80.0, 342.0, 1332.0, 309.0, 1333.0, 429.0, 81.0, 472.0]\n",
      "Text detectat: TEMELOR la\n",
      "Coordonate bounding box: [132.0, 590.0, 1043.0, 584.0, 1044.0, 718.0, 132.0, 726.0]\n",
      "Text detectat: LABORA toarele de\n",
      "Coordonate bounding box: [80.0, 915.0, 1003.0, 923.0, 1001.0, 1040.0, 77.0, 1017.0]\n",
      "Text detectat: Inteligenta Artificialà!\n",
      "Coordonate bounding box: [103.0, 1129.0, 1450.0, 1155.0, 1447.0, 1293.0, 99.0, 1259.0]\n",
      "Scor IoU 1: 0.46\n",
      "Scor IoU 2: 0.82\n",
      "Scor IoU 3: 0.86\n",
      "Scor IoU 4: 0.66\n",
      "Text detectat: Succes in resolvarea\n",
      "Coordonate bounding box: [170.0, 613.0, 2690.0, 578.0, 2692.0, 896.0, 170.0, 946.0]\n",
      "Text detectat: TEMELOR la\n",
      "Coordonate bounding box: [256.0, 1155.0, 2116.0, 1152.0, 2117.0, 1470.0, 256.0, 1474.0]\n",
      "Text detectat: LABORA toarele de\n",
      "Coordonate bounding box: [160.0, 1818.0, 2008.0, 1818.0, 2004.0, 2074.0, 157.0, 2045.0]\n",
      "Text detectat: Inteligenta Artificialà!\n",
      "Coordonate bounding box: [215.0, 2263.0, 2899.0, 2306.0, 2893.0, 2589.0, 208.0, 2517.0]\n",
      "Scor IoU 1: 0.00\n",
      "Scor IoU 2: 0.00\n",
      "Scor IoU 3: 0.00\n",
      "Scor IoU 4: 0.00\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
